{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import imdb\ntop_words = 10000\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The reason the inner lists contain numbers rather than text is that you don't train a neural network with text; you train it with numbers. Specifically, you train it with tensors. In this case, each review is a 1-dimensional tensor (think of a 1-dimensional array) containing integers identifying the words contained in the review. To demonstrate, type the following Python statement into an empty cell and execute it to see the integers representing the first review in the training set:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train[0]",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "[1,\n 14,\n 22,\n 16,\n 43,\n 530,\n 973,\n 1622,\n 1385,\n 65,\n 458,\n 4468,\n 66,\n 3941,\n 4,\n 173,\n 36,\n 256,\n 5,\n 25,\n 100,\n 43,\n 838,\n 112,\n 50,\n 670,\n 2,\n 9,\n 35,\n 480,\n 284,\n 5,\n 150,\n 4,\n 172,\n 112,\n 167,\n 2,\n 336,\n 385,\n 39,\n 4,\n 172,\n 4536,\n 1111,\n 17,\n 546,\n 38,\n 13,\n 447,\n 4,\n 192,\n 50,\n 16,\n 6,\n 147,\n 2025,\n 19,\n 14,\n 22,\n 4,\n 1920,\n 4613,\n 469,\n 4,\n 22,\n 71,\n 87,\n 12,\n 16,\n 43,\n 530,\n 38,\n 76,\n 15,\n 13,\n 1247,\n 4,\n 22,\n 17,\n 515,\n 17,\n 12,\n 16,\n 626,\n 18,\n 2,\n 5,\n 62,\n 386,\n 12,\n 8,\n 316,\n 8,\n 106,\n 5,\n 4,\n 2223,\n 5244,\n 16,\n 480,\n 66,\n 3785,\n 33,\n 4,\n 130,\n 12,\n 16,\n 38,\n 619,\n 5,\n 25,\n 124,\n 51,\n 36,\n 135,\n 48,\n 25,\n 1415,\n 33,\n 6,\n 22,\n 12,\n 215,\n 28,\n 77,\n 52,\n 5,\n 14,\n 407,\n 16,\n 82,\n 2,\n 8,\n 4,\n 107,\n 117,\n 5952,\n 15,\n 256,\n 4,\n 2,\n 7,\n 3766,\n 5,\n 723,\n 36,\n 71,\n 43,\n 530,\n 476,\n 26,\n 400,\n 317,\n 46,\n 7,\n 4,\n 2,\n 1029,\n 13,\n 104,\n 88,\n 4,\n 381,\n 15,\n 297,\n 98,\n 32,\n 2071,\n 56,\n 26,\n 141,\n 6,\n 194,\n 7486,\n 18,\n 4,\n 226,\n 22,\n 21,\n 134,\n 476,\n 26,\n 480,\n 5,\n 144,\n 30,\n 5535,\n 18,\n 51,\n 36,\n 28,\n 224,\n 92,\n 25,\n 104,\n 4,\n 226,\n 65,\n 16,\n 38,\n 1334,\n 88,\n 12,\n 16,\n 283,\n 5,\n 16,\n 4472,\n 113,\n 103,\n 32,\n 15,\n 16,\n 5345,\n 19,\n 178,\n 32]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Integers comprising the first review in the IMDB training set\n\nThe first number in the list — 1 — doesn't represent a word at all. It marks the start of the review and is the same for every review in the dataset. The numbers 0 and 2 are reserved as well, and you subtract 3 from the other numbers to map an integer in a review to the corresponding integer in the dictionary. The second number — 14 — references the word that corresponds to the number 11 in the dictionary, the third number represents the word assigned the number 19 in the dictionary, and so on."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "imdb.get_word_index()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "{'fawn': 34701,\n 'tsukino': 52006,\n 'nunnery': 52007,\n 'sonja': 16816,\n 'vani': 63951,\n 'woods': 1408,\n 'spiders': 16115,\n 'hanging': 2345,\n 'woody': 2289,\n 'trawling': 52008,\n \"hold's\": 52009,\n 'comically': 11307,\n 'localized': 40830,\n 'disobeying': 30568,\n \"'royale\": 52010,\n \"harpo's\": 40831,\n 'canet': 52011,\n 'aileen': 19313,\n 'acurately': 52012,\n \"diplomat's\": 52013,\n 'rickman': 25242,\n 'arranged': 6746,\n 'rumbustious': 52014,\n 'familiarness': 52015,\n \"spider'\": 52016,\n 'hahahah': 68804,\n \"wood'\": 52017,\n 'transvestism': 40833,\n \"hangin'\": 34702,\n 'bringing': 2338,\n 'seamier': 40834,\n 'wooded': 34703,\n 'bravora': 52018,\n 'grueling': 16817,\n 'wooden': 1636,\n 'wednesday': 16818,\n \"'prix\": 52019,\n 'altagracia': 34704,\n 'circuitry': 52020,\n 'crotch': 11585,\n 'busybody': 57766,\n \"tart'n'tangy\": 52021,\n 'burgade': 14129,\n 'thrace': 52023,\n \"tom's\": 11038,\n 'snuggles': 52025,\n 'francesco': 29114,\n 'complainers': 52027,\n 'templarios': 52125,\n '272': 40835,\n '273': 52028,\n 'zaniacs': 52130,\n '275': 34706,\n 'consenting': 27631,\n 'snuggled': 40836,\n 'inanimate': 15492,\n 'uality': 52030,\n 'bronte': 11926,\n 'errors': 4010,\n 'dialogs': 3230,\n \"yomada's\": 52031,\n \"madman's\": 34707,\n 'dialoge': 30585,\n 'usenet': 52033,\n 'videodrome': 40837,\n \"kid'\": 26338,\n 'pawed': 52034,\n \"'girlfriend'\": 30569,\n \"'pleasure\": 52035,\n \"'reloaded'\": 52036,\n \"kazakos'\": 40839,\n 'rocque': 52037,\n 'mailings': 52038,\n 'brainwashed': 11927,\n 'mcanally': 16819,\n \"tom''\": 52039,\n 'kurupt': 25243,\n 'affiliated': 21905,\n 'babaganoosh': 52040,\n \"noe's\": 40840,\n 'quart': 40841,\n 'kids': 359,\n 'uplifting': 5034,\n 'controversy': 7093,\n 'kida': 21906,\n 'kidd': 23379,\n \"error'\": 52041,\n 'neurologist': 52042,\n 'spotty': 18510,\n 'cobblers': 30570,\n 'projection': 9878,\n 'fastforwarding': 40842,\n 'sters': 52043,\n \"eggar's\": 52044,\n 'etherything': 52045,\n 'gateshead': 40843,\n 'airball': 34708,\n 'unsinkable': 25244,\n 'stern': 7180,\n \"cervi's\": 52046,\n 'dnd': 40844,\n 'dna': 11586,\n 'insecurity': 20598,\n \"'reboot'\": 52047,\n 'trelkovsky': 11037,\n 'jaekel': 52048,\n 'sidebars': 52049,\n \"sforza's\": 52050,\n 'distortions': 17633,\n 'mutinies': 52051,\n 'sermons': 30602,\n '7ft': 40846,\n 'boobage': 52052,\n \"o'bannon's\": 52053,\n 'populations': 23380,\n 'chulak': 52054,\n 'mesmerize': 27633,\n 'quinnell': 52055,\n 'yahoo': 10307,\n 'meteorologist': 52057,\n 'beswick': 42577,\n 'boorman': 15493,\n 'voicework': 40847,\n \"ster'\": 52058,\n 'blustering': 22922,\n 'hj': 52059,\n 'intake': 27634,\n 'morally': 5621,\n 'jumbling': 40849,\n 'bowersock': 52060,\n \"'porky's'\": 52061,\n 'gershon': 16821,\n 'ludicrosity': 40850,\n 'coprophilia': 52062,\n 'expressively': 40851,\n \"india's\": 19500,\n \"post's\": 34710,\n 'wana': 52063,\n 'wang': 5283,\n 'wand': 30571,\n 'wane': 25245,\n 'edgeways': 52321,\n 'titanium': 34711,\n 'pinta': 40852,\n 'want': 178,\n 'pinto': 30572,\n 'whoopdedoodles': 52065,\n 'tchaikovsky': 21908,\n 'travel': 2103,\n \"'victory'\": 52066,\n 'copious': 11928,\n 'gouge': 22433,\n \"chapters'\": 52067,\n 'barbra': 6702,\n 'uselessness': 30573,\n \"wan'\": 52068,\n 'assimilated': 27635,\n 'petiot': 16116,\n 'most\\x85and': 52069,\n 'dinosaurs': 3930,\n 'wrong': 352,\n 'seda': 52070,\n 'stollen': 52071,\n 'sentencing': 34712,\n 'ouroboros': 40853,\n 'assimilates': 40854,\n 'colorfully': 40855,\n 'glenne': 27636,\n 'dongen': 52072,\n 'subplots': 4760,\n 'kiloton': 52073,\n 'chandon': 23381,\n \"effect'\": 34713,\n 'snugly': 27637,\n 'kuei': 40856,\n 'welcomed': 9092,\n 'dishonor': 30071,\n 'concurrence': 52075,\n 'stoicism': 23382,\n \"guys'\": 14896,\n \"beroemd'\": 52077,\n 'butcher': 6703,\n \"melfi's\": 40857,\n 'aargh': 30623,\n 'playhouse': 20599,\n 'wickedly': 11308,\n 'fit': 1180,\n 'labratory': 52078,\n 'lifeline': 40859,\n 'screaming': 1927,\n 'fix': 4287,\n 'cineliterate': 52079,\n 'fic': 52080,\n 'fia': 52081,\n 'fig': 34714,\n 'fmvs': 52082,\n 'fie': 52083,\n 'reentered': 52084,\n 'fin': 30574,\n 'doctresses': 52085,\n 'fil': 52086,\n 'zucker': 12606,\n 'ached': 31931,\n 'counsil': 52088,\n 'paterfamilias': 52089,\n 'songwriter': 13885,\n 'shivam': 34715,\n 'hurting': 9654,\n 'effects': 299,\n 'slauther': 52090,\n \"'flame'\": 52091,\n 'sommerset': 52092,\n 'interwhined': 52093,\n 'whacking': 27638,\n 'bartok': 52094,\n 'barton': 8775,\n 'frewer': 21909,\n \"fi'\": 52095,\n 'ingrid': 6192,\n 'stribor': 30575,\n 'approporiately': 52096,\n 'wobblyhand': 52097,\n 'tantalisingly': 52098,\n 'ankylosaurus': 52099,\n 'parasites': 17634,\n 'childen': 52100,\n \"jenkins'\": 52101,\n 'metafiction': 52102,\n 'golem': 17635,\n 'indiscretion': 40860,\n \"reeves'\": 23383,\n \"inamorata's\": 57781,\n 'brittannica': 52104,\n 'adapt': 7916,\n \"russo's\": 30576,\n 'guitarists': 48246,\n 'abbott': 10553,\n 'abbots': 40861,\n 'lanisha': 17649,\n 'magickal': 40863,\n 'mattter': 52105,\n \"'willy\": 52106,\n 'pumpkins': 34716,\n 'stuntpeople': 52107,\n 'estimate': 30577,\n 'ugghhh': 40864,\n 'gameplay': 11309,\n \"wern't\": 52108,\n \"n'sync\": 40865,\n 'sickeningly': 16117,\n 'chiara': 40866,\n 'disturbed': 4011,\n 'portmanteau': 40867,\n 'ineffectively': 52109,\n \"duchonvey's\": 82143,\n \"nasty'\": 37519,\n 'purpose': 1285,\n 'lazers': 52112,\n 'lightened': 28105,\n 'kaliganj': 52113,\n 'popularism': 52114,\n \"damme's\": 18511,\n 'stylistics': 30578,\n 'mindgaming': 52115,\n 'spoilerish': 46449,\n \"'corny'\": 52117,\n 'boerner': 34718,\n 'olds': 6792,\n 'bakelite': 52118,\n 'renovated': 27639,\n 'forrester': 27640,\n \"lumiere's\": 52119,\n 'gaskets': 52024,\n 'needed': 884,\n 'smight': 34719,\n 'master': 1297,\n \"edie's\": 25905,\n 'seeber': 40868,\n 'hiya': 52120,\n 'fuzziness': 52121,\n 'genesis': 14897,\n 'rewards': 12607,\n 'enthrall': 30579,\n \"'about\": 40869,\n \"recollection's\": 52122,\n 'mutilated': 11039,\n 'fatherlands': 52123,\n \"fischer's\": 52124,\n 'positively': 5399,\n '270': 34705,\n 'ahmed': 34720,\n 'zatoichi': 9836,\n 'bannister': 13886,\n 'anniversaries': 52127,\n \"helm's\": 30580,\n \"'work'\": 52128,\n 'exclaimed': 34721,\n \"'unfunny'\": 52129,\n '274': 52029,\n 'feeling': 544,\n \"wanda's\": 52131,\n 'dolan': 33266,\n '278': 52133,\n 'peacoat': 52134,\n 'brawny': 40870,\n 'mishra': 40871,\n 'worlders': 40872,\n 'protags': 52135,\n 'skullcap': 52136,\n 'dastagir': 57596,\n 'affairs': 5622,\n 'wholesome': 7799,\n 'hymen': 52137,\n 'paramedics': 25246,\n 'unpersons': 52138,\n 'heavyarms': 52139,\n 'affaire': 52140,\n 'coulisses': 52141,\n 'hymer': 40873,\n 'kremlin': 52142,\n 'shipments': 30581,\n 'pixilated': 52143,\n \"'00s\": 30582,\n 'diminishing': 18512,\n 'cinematic': 1357,\n 'resonates': 14898,\n 'simplify': 40874,\n \"nature'\": 40875,\n 'temptresses': 40876,\n 'reverence': 16822,\n 'resonated': 19502,\n 'dailey': 34722,\n '2\\x85': 52144,\n 'treize': 27641,\n 'majo': 52145,\n 'kiya': 21910,\n 'woolnough': 52146,\n 'thanatos': 39797,\n 'sandoval': 35731,\n 'dorama': 40879,\n \"o'shaughnessy\": 52147,\n 'tech': 4988,\n 'fugitives': 32018,\n 'teck': 30583,\n \"'e'\": 76125,\n 'doesn’t': 40881,\n 'purged': 52149,\n 'saying': 657,\n \"martians'\": 41095,\n 'norliss': 23418,\n 'dickey': 27642,\n 'dicker': 52152,\n \"'sependipity\": 52153,\n 'padded': 8422,\n 'ordell': 57792,\n \"sturges'\": 40882,\n 'independentcritics': 52154,\n 'tempted': 5745,\n \"atkinson's\": 34724,\n 'hounded': 25247,\n 'apace': 52155,\n 'clicked': 15494,\n \"'humor'\": 30584,\n \"martino's\": 17177,\n \"'supporting\": 52156,\n 'warmongering': 52032,\n \"zemeckis's\": 34725,\n 'lube': 21911,\n 'shocky': 52157,\n 'plate': 7476,\n 'plata': 40883,\n 'sturgess': 40884,\n \"nerds'\": 40885,\n 'plato': 20600,\n 'plath': 34726,\n 'platt': 40886,\n 'mcnab': 52159,\n 'clumsiness': 27643,\n 'altogether': 3899,\n 'massacring': 42584,\n 'bicenntinial': 52160,\n 'skaal': 40887,\n 'droning': 14360,\n 'lds': 8776,\n 'jaguar': 21912,\n \"cale's\": 34727,\n 'nicely': 1777,\n 'mummy': 4588,\n \"lot's\": 18513,\n 'patch': 10086,\n 'kerkhof': 50202,\n \"leader's\": 52161,\n \"'movie\": 27644,\n 'uncomfirmed': 52162,\n 'heirloom': 40888,\n 'wrangle': 47360,\n 'emotion\\x85': 52163,\n \"'stargate'\": 52164,\n 'pinoy': 40889,\n 'conchatta': 40890,\n 'broeke': 41128,\n 'advisedly': 40891,\n \"barker's\": 17636,\n 'descours': 52166,\n 'lots': 772,\n 'lotr': 9259,\n 'irs': 9879,\n 'lott': 52167,\n 'xvi': 40892,\n 'irk': 34728,\n 'irl': 52168,\n 'ira': 6887,\n 'belzer': 21913,\n 'irc': 52169,\n 'ire': 27645,\n 'requisites': 40893,\n 'discipline': 7693,\n 'lyoko': 52961,\n 'extend': 11310,\n 'nature': 873,\n \"'dickie'\": 52170,\n 'optimist': 40894,\n 'lapping': 30586,\n 'superficial': 3900,\n 'vestment': 52171,\n 'extent': 2823,\n 'tendons': 52172,\n \"heller's\": 52173,\n 'quagmires': 52174,\n 'miyako': 52175,\n 'moocow': 20601,\n \"coles'\": 52176,\n 'lookit': 40895,\n 'ravenously': 52177,\n 'levitating': 40896,\n 'perfunctorily': 52178,\n 'lookin': 30587,\n \"lot'\": 40898,\n 'lookie': 52179,\n 'fearlessly': 34870,\n 'libyan': 52181,\n 'fondles': 40899,\n 'gopher': 35714,\n 'wearying': 40901,\n \"nz's\": 52182,\n 'minuses': 27646,\n 'puposelessly': 52183,\n 'shandling': 52184,\n 'decapitates': 31268,\n 'humming': 11929,\n \"'nother\": 40902,\n 'smackdown': 21914,\n 'underdone': 30588,\n 'frf': 40903,\n 'triviality': 52185,\n 'fro': 25248,\n 'bothers': 8777,\n \"'kensington\": 52186,\n 'much': 73,\n 'muco': 34730,\n 'wiseguy': 22615,\n \"richie's\": 27648,\n 'tonino': 40904,\n 'unleavened': 52187,\n 'fry': 11587,\n \"'tv'\": 40905,\n 'toning': 40906,\n 'obese': 14361,\n 'sensationalized': 30589,\n 'spiv': 40907,\n 'spit': 6259,\n 'arkin': 7364,\n 'charleton': 21915,\n 'jeon': 16823,\n 'boardroom': 21916,\n 'doubts': 4989,\n 'spin': 3084,\n 'hepo': 53083,\n 'wildcat': 27649,\n 'venoms': 10584,\n 'misconstrues': 52191,\n 'mesmerising': 18514,\n 'misconstrued': 40908,\n 'rescinds': 52192,\n 'prostrate': 52193,\n 'majid': 40909,\n 'climbed': 16479,\n 'canoeing': 34731,\n 'majin': 52195,\n 'animie': 57804,\n 'sylke': 40910,\n 'conditioned': 14899,\n 'waddell': 40911,\n '3\\x85': 52196,\n 'hyperdrive': 41188,\n 'conditioner': 34732,\n 'bricklayer': 53153,\n 'hong': 2576,\n 'memoriam': 52198,\n 'inventively': 30592,\n \"levant's\": 25249,\n 'portobello': 20638,\n 'remand': 52200,\n 'mummified': 19504,\n 'honk': 27650,\n 'spews': 19505,\n 'visitations': 40912,\n 'mummifies': 52201,\n 'cavanaugh': 25250,\n 'zeon': 23385,\n \"jungle's\": 40913,\n 'viertel': 34733,\n 'frenchmen': 27651,\n 'torpedoes': 52202,\n 'schlessinger': 52203,\n 'torpedoed': 34734,\n 'blister': 69876,\n 'cinefest': 52204,\n 'furlough': 34735,\n 'mainsequence': 52205,\n 'mentors': 40914,\n 'academic': 9094,\n 'stillness': 20602,\n 'academia': 40915,\n 'lonelier': 52206,\n 'nibby': 52207,\n \"losers'\": 52208,\n 'cineastes': 40916,\n 'corporate': 4449,\n 'massaging': 40917,\n 'bellow': 30593,\n 'absurdities': 19506,\n 'expetations': 53241,\n 'nyfiken': 40918,\n 'mehras': 75638,\n 'lasse': 52209,\n 'visability': 52210,\n 'militarily': 33946,\n \"elder'\": 52211,\n 'gainsbourg': 19023,\n 'hah': 20603,\n 'hai': 13420,\n 'haj': 34736,\n 'hak': 25251,\n 'hal': 4311,\n 'ham': 4892,\n 'duffer': 53259,\n 'haa': 52213,\n 'had': 66,\n 'advancement': 11930,\n 'hag': 16825,\n \"hand'\": 25252,\n 'hay': 13421,\n 'mcnamara': 20604,\n \"mozart's\": 52214,\n 'duffel': 30731,\n 'haq': 30594,\n 'har': 13887,\n 'has': 44,\n 'hat': 2401,\n 'hav': 40919,\n 'haw': 30595,\n 'figtings': 52215,\n 'elders': 15495,\n 'underpanted': 52216,\n 'pninson': 52217,\n 'unequivocally': 27652,\n \"barbara's\": 23673,\n \"bello'\": 52219,\n 'indicative': 12997,\n 'yawnfest': 40920,\n 'hexploitation': 52220,\n \"loder's\": 52221,\n 'sleuthing': 27653,\n \"justin's\": 32622,\n \"'ball\": 52222,\n \"'summer\": 52223,\n \"'demons'\": 34935,\n \"mormon's\": 52225,\n \"laughton's\": 34737,\n 'debell': 52226,\n 'shipyard': 39724,\n 'unabashedly': 30597,\n 'disks': 40401,\n 'crowd': 2290,\n 'crowe': 10087,\n \"vancouver's\": 56434,\n 'mosques': 34738,\n 'crown': 6627,\n 'culpas': 52227,\n 'crows': 27654,\n 'surrell': 53344,\n 'flowless': 52229,\n 'sheirk': 52230,\n \"'three\": 40923,\n \"peterson'\": 52231,\n 'ooverall': 52232,\n 'perchance': 40924,\n 'bottom': 1321,\n 'chabert': 53363,\n 'sneha': 52233,\n 'inhuman': 13888,\n 'ichii': 52234,\n 'ursla': 52235,\n 'completly': 30598,\n 'moviedom': 40925,\n 'raddick': 52236,\n 'brundage': 51995,\n 'brigades': 40926,\n 'starring': 1181,\n \"'goal'\": 52237,\n 'caskets': 52238,\n 'willcock': 52239,\n \"threesome's\": 52240,\n \"mosque'\": 52241,\n \"cover's\": 52242,\n 'spaceships': 17637,\n 'anomalous': 40927,\n 'ptsd': 27655,\n 'shirdan': 52243,\n 'obscenity': 21962,\n 'lemmings': 30599,\n 'duccio': 30600,\n \"levene's\": 52244,\n \"'gorby'\": 52245,\n \"teenager's\": 25255,\n 'marshall': 5340,\n 'honeymoon': 9095,\n 'shoots': 3231,\n 'despised': 12258,\n 'okabasho': 52246,\n 'fabric': 8289,\n 'cannavale': 18515,\n 'raped': 3537,\n \"tutt's\": 52247,\n 'grasping': 17638,\n 'despises': 18516,\n \"thief's\": 40928,\n 'rapes': 8926,\n 'raper': 52248,\n \"eyre'\": 27656,\n 'walchek': 52249,\n \"elmo's\": 23386,\n 'perfumes': 40929,\n 'spurting': 21918,\n \"exposition'\\x85\": 52250,\n 'denoting': 52251,\n 'thesaurus': 34740,\n \"shoot'\": 40930,\n 'bonejack': 49759,\n 'simpsonian': 52253,\n 'hebetude': 30601,\n \"hallow's\": 34741,\n 'desperation\\x85': 52254,\n 'incinerator': 34742,\n 'congratulations': 10308,\n 'humbled': 52255,\n \"else's\": 5924,\n 'trelkovski': 40845,\n \"rape'\": 52256,\n \"'chapters'\": 59386,\n '1600s': 52257,\n 'martian': 7253,\n 'nicest': 25256,\n 'eyred': 52259,\n 'passenger': 9457,\n 'disgrace': 6041,\n 'moderne': 52260,\n 'barrymore': 5120,\n 'yankovich': 52261,\n 'moderns': 40931,\n 'studliest': 52262,\n 'bedsheet': 52263,\n 'decapitation': 14900,\n 'slurring': 52264,\n \"'nunsploitation'\": 52265,\n \"'character'\": 34743,\n 'cambodia': 9880,\n 'rebelious': 52266,\n 'pasadena': 27657,\n 'crowne': 40932,\n \"'bedchamber\": 52267,\n 'conjectural': 52268,\n 'appologize': 52269,\n 'halfassing': 52270,\n 'paycheque': 57816,\n 'palms': 20606,\n \"'islands\": 52271,\n 'hawked': 40933,\n 'palme': 21919,\n 'conservatively': 40934,\n 'larp': 64007,\n 'palma': 5558,\n 'smelling': 21920,\n 'aragorn': 12998,\n 'hawker': 52272,\n 'hawkes': 52273,\n 'explosions': 3975,\n 'loren': 8059,\n \"pyle's\": 52274,\n 'shootout': 6704,\n \"mike's\": 18517,\n \"driscoll's\": 52275,\n 'cogsworth': 40935,\n \"britian's\": 52276,\n 'childs': 34744,\n \"portrait's\": 52277,\n 'chain': 3626,\n 'whoever': 2497,\n 'puttered': 52278,\n 'childe': 52279,\n 'maywether': 52280,\n 'chair': 3036,\n \"rance's\": 52281,\n 'machu': 34745,\n 'ballet': 4517,\n 'grapples': 34746,\n 'summerize': 76152,\n 'freelance': 30603,\n \"andrea's\": 52283,\n '\\x91very': 52284,\n 'coolidge': 45879,\n 'mache': 18518,\n 'balled': 52285,\n 'grappled': 40937,\n 'macha': 18519,\n 'underlining': 21921,\n 'macho': 5623,\n 'oversight': 19507,\n 'machi': 25257,\n 'verbally': 11311,\n 'tenacious': 21922,\n 'windshields': 40938,\n 'paychecks': 18557,\n 'jerk': 3396,\n \"good'\": 11931,\n 'prancer': 34748,\n 'prances': 21923,\n 'olympus': 52286,\n 'lark': 21924,\n 'embark': 10785,\n 'gloomy': 7365,\n 'jehaan': 52287,\n 'turaqui': 52288,\n \"child'\": 20607,\n 'locked': 2894,\n 'pranced': 52289,\n 'exact': 2588,\n 'unattuned': 52290,\n 'minute': 783,\n 'skewed': 16118,\n 'hodgins': 40940,\n 'skewer': 34749,\n 'think\\x85': 52291,\n 'rosenstein': 38765,\n 'helmit': 52292,\n 'wrestlemanias': 34750,\n 'hindered': 16826,\n \"martha's\": 30604,\n 'cheree': 52293,\n \"pluckin'\": 52294,\n 'ogles': 40941,\n 'heavyweight': 11932,\n 'aada': 82190,\n 'chopping': 11312,\n 'strongboy': 61534,\n 'hegemonic': 41342,\n 'adorns': 40942,\n 'xxth': 41346,\n 'nobuhiro': 34751,\n 'capitães': 52298,\n 'kavogianni': 52299,\n 'antwerp': 13422,\n 'celebrated': 6538,\n 'roarke': 52300,\n 'baggins': 40943,\n 'cheeseburgers': 31270,\n 'matras': 52301,\n \"nineties'\": 52302,\n \"'craig'\": 52303,\n 'celebrates': 12999,\n 'unintentionally': 3383,\n 'drafted': 14362,\n 'climby': 52304,\n '303': 52305,\n 'oldies': 18520,\n 'climbs': 9096,\n 'honour': 9655,\n 'plucking': 34752,\n '305': 30074,\n 'address': 5514,\n 'menjou': 40944,\n \"'freak'\": 42592,\n 'dwindling': 19508,\n 'benson': 9458,\n 'white’s': 52307,\n 'shamelessness': 40945,\n 'impacted': 21925,\n 'upatz': 52308,\n 'cusack': 3840,\n \"flavia's\": 37567,\n 'effette': 52309,\n 'influx': 34753,\n 'boooooooo': 52310,\n 'dimitrova': 52311,\n 'houseman': 13423,\n 'bigas': 25259,\n 'boylen': 52312,\n 'phillipenes': 52313,\n 'fakery': 40946,\n \"grandpa's\": 27658,\n 'darnell': 27659,\n 'undergone': 19509,\n 'handbags': 52315,\n 'perished': 21926,\n 'pooped': 37778,\n 'vigour': 27660,\n 'opposed': 3627,\n 'etude': 52316,\n \"caine's\": 11799,\n 'doozers': 52317,\n 'photojournals': 34754,\n 'perishes': 52318,\n 'constrains': 34755,\n 'migenes': 40948,\n 'consoled': 30605,\n 'alastair': 16827,\n 'wvs': 52319,\n 'ooooooh': 52320,\n 'approving': 34756,\n 'consoles': 40949,\n 'disparagement': 52064,\n 'futureistic': 52322,\n 'rebounding': 52323,\n \"'date\": 52324,\n 'gregoire': 52325,\n 'rutherford': 21927,\n 'americanised': 34757,\n 'novikov': 82196,\n 'following': 1042,\n 'munroe': 34758,\n \"morita'\": 52326,\n 'christenssen': 52327,\n 'oatmeal': 23106,\n 'fossey': 25260,\n 'livered': 40950,\n 'listens': 13000,\n \"'marci\": 76164,\n \"otis's\": 52330,\n 'thanking': 23387,\n 'maude': 16019,\n 'extensions': 34759,\n 'ameteurish': 52332,\n \"commender's\": 52333,\n 'agricultural': 27661,\n 'convincingly': 4518,\n 'fueled': 17639,\n 'mahattan': 54014,\n \"paris's\": 40952,\n 'vulkan': 52336,\n 'stapes': 52337,\n 'odysessy': 52338,\n 'harmon': 12259,\n 'surfing': 4252,\n 'halloran': 23494,\n 'unbelieveably': 49580,\n \"'offed'\": 52339,\n 'quadrant': 30607,\n 'inhabiting': 19510,\n 'nebbish': 34760,\n 'forebears': 40953,\n 'skirmish': 34761,\n 'ocassionally': 52340,\n \"'resist\": 52341,\n 'impactful': 21928,\n 'spicier': 52342,\n 'touristy': 40954,\n \"'football'\": 52343,\n 'webpage': 40955,\n 'exurbia': 52345,\n 'jucier': 52346,\n 'professors': 14901,\n 'structuring': 34762,\n 'jig': 30608,\n 'overlord': 40956,\n 'disconnect': 25261,\n 'sniffle': 82201,\n 'slimeball': 40957,\n 'jia': 40958,\n 'milked': 16828,\n 'banjoes': 40959,\n 'jim': 1237,\n 'workforces': 52348,\n 'jip': 52349,\n 'rotweiller': 52350,\n 'mundaneness': 34763,\n \"'ninja'\": 52351,\n \"dead'\": 11040,\n \"cipriani's\": 40960,\n 'modestly': 20608,\n \"professor'\": 52352,\n 'shacked': 40961,\n 'bashful': 34764,\n 'sorter': 23388,\n 'overpowering': 16120,\n 'workmanlike': 18521,\n 'henpecked': 27662,\n 'sorted': 18522,\n \"jōb's\": 52354,\n \"'always\": 52355,\n \"'baptists\": 34765,\n 'dreamcatchers': 52356,\n \"'silence'\": 52357,\n 'hickory': 21929,\n 'fun\\x97yet': 52358,\n 'breakumentary': 52359,\n 'didn': 15496,\n 'didi': 52360,\n 'pealing': 52361,\n 'dispite': 40962,\n \"italy's\": 25262,\n 'instability': 21930,\n 'quarter': 6539,\n 'quartet': 12608,\n 'padmé': 52362,\n \"'bleedmedry\": 52363,\n 'pahalniuk': 52364,\n 'honduras': 52365,\n 'bursting': 10786,\n \"pablo's\": 41465,\n 'irremediably': 52367,\n 'presages': 40963,\n 'bowlegged': 57832,\n 'dalip': 65183,\n 'entering': 6260,\n 'newsradio': 76172,\n 'presaged': 54150,\n \"giallo's\": 27663,\n 'bouyant': 40964,\n 'amerterish': 52368,\n 'rajni': 18523,\n 'leeves': 30610,\n 'macauley': 34767,\n 'seriously': 612,\n 'sugercoma': 52369,\n 'grimstead': 52370,\n \"'fairy'\": 52371,\n 'zenda': 30611,\n \"'twins'\": 52372,\n 'realisation': 17640,\n 'highsmith': 27664,\n 'raunchy': 7817,\n 'incentives': 40965,\n 'flatson': 52374,\n 'snooker': 35097,\n 'crazies': 16829,\n 'crazier': 14902,\n 'grandma': 7094,\n 'napunsaktha': 52375,\n 'workmanship': 30612,\n 'reisner': 52376,\n \"sanford's\": 61306,\n '\\x91doña': 52377,\n 'modest': 6108,\n \"everything's\": 19153,\n 'hamer': 40966,\n \"couldn't'\": 52379,\n 'quibble': 13001,\n 'socking': 52380,\n 'tingler': 21931,\n 'gutman': 52381,\n 'lachlan': 40967,\n 'tableaus': 52382,\n 'headbanger': 52383,\n 'spoken': 2847,\n 'cerebrally': 34768,\n \"'road\": 23490,\n 'tableaux': 21932,\n \"proust's\": 40968,\n 'periodical': 40969,\n \"shoveller's\": 52385,\n 'tamara': 25263,\n 'affords': 17641,\n 'concert': 3249,\n \"yara's\": 87955,\n 'someome': 52386,\n 'lingering': 8424,\n \"abraham's\": 41511,\n 'beesley': 34769,\n 'cherbourg': 34770,\n 'kagan': 28624,\n 'snatch': 9097,\n \"miyazaki's\": 9260,\n 'absorbs': 25264,\n \"koltai's\": 40970,\n 'tingled': 64027,\n 'crossroads': 19511,\n 'rehab': 16121,\n 'falworth': 52389,\n 'sequals': 52390,\n ...}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As you have seen, each review in the dataset is encoded as a collection of integers rather than words. Is it possible to reverse-encode a review so you can see the original text that comprised it? Enter the following statements into a new cell and execute them to show the first review in x_train in textual format:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "word_dict = imdb.get_word_index()\nword_dict = { key:(value + 3) for key, value in word_dict.items() }\nword_dict[''] = 0  # Padding\nword_dict['>'] = 1 # Start\nword_dict['?'] = 2 # Unknown word\nreverse_word_dict = { value:key for key, value in word_dict.items() }\nprint(' '.join(reverse_word_dict[id] for id in x_train[0]))",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The reviews are \"clean\" in the sense that letters have been converted to lowercase and punctuation characters removed. But they are not ready to train a neural network to analyze text for sentiment. When you train a neural network with collection of tensors, each tensor needs to be the same length. At present, the lists representing reviews in x_train and x_test have varying lengths.\n\nFortunately, Keras includes a function that takes a list of lists as input and converts the inner lists to a specified length by truncating them if necessary or padding them with 0s. Enter the following code into the notebook and run it to force all the lists representing movie reviews in x_train and x_test to a length of 500 integers:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import sequence\nmax_review_length = 500\nx_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\nx_test = sequence.pad_sequences(x_test, maxlen=max_review_length)",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that the training and testing data is prepared, it is time to build the model! Run the following code in the notebook to create a neural network that performs sentiment analysis:\n\nNOTE: In a neural network, the activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Flatten\n\nembedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\nmodel.add(Flatten())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\nprint(model.summary())\n",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 500, 32)           320000    \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 16000)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 16)                256016    \n_________________________________________________________________\ndense_5 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 576,305\nTrainable params: 576,305\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This code is the essence of how you construct a neural network with Keras. It first instantiates a Sequential object representing a \"sequential\" model — one that is composed of an end-to-end stack of layers in which the output from one layer provides input to the next.\n\nThe next several statements add layers to the model. First is an embedding layer, which is crucial to neural networks that process words. The embedding layer essentially maps many-dimensional arrays containing integer word indexes into floating-point arrays containing fewer dimensions. It also allows words with similar meanings to be treated alike. A full treatment of word embeddings is beyond the scope of this lab, but you can learn more by reading Why You Need to Start Using Embedding Layers. If you prefer a more scholarly explanation, refer to Efficient Estimation of Word Representations in Vector Space. The call to Flatten following the addition of the embedding layer reshapes the output for input to the next layer.\n\nThe next three layers added to the model are dense layers, also known as fully connected layers. These are the traditional layers that are common in neural networks. Each layer contains n nodes or neurons, and each neuron receives input from every neuron in the previous layer, hence the term \"fully connected.\" It is these layers that permit a neural network to \"learn\" from input data by iteratively guessing at the output, checking the results, and fine-tuning the connections to produce better results. The first two dense layers in this network contain 16 neurons each. This number was arbitrarily chosen; you might be able to improve the accuracy of the model by experimenting with different sizes. The final dense layer contains just one neuron because the ultimate goal of the network is to predict one output — namely, a sentiment score from 0.0 to 1.0."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The call to the compile function \"compiles\" the model by specifying important parameters such as which optimizer to use and what metrics to use to judge the accuracy of the model in each training step. Training doesn't begin until you call the model's fit function, so the compile call typically executes quickly."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#  Now call the fit function to train the neural network:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=128)",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/3\n25000/25000 [==============================] - 10s 393us/step - loss: 0.5579 - acc: 0.6690 - val_loss: 0.3252 - val_acc: 0.8578\nEpoch 2/3\n25000/25000 [==============================] - 9s 375us/step - loss: 0.2050 - acc: 0.9212 - val_loss: 0.2852 - val_acc: 0.8806\nEpoch 3/3\n25000/25000 [==============================] - 9s 365us/step - loss: 0.0682 - acc: 0.9819 - val_loss: 0.3500 - val_acc: 0.8727\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This model is unusual in that it learns well with just a few epochs. The training accuracy quickly zooms to near 100%, while the validation accuracy goes up for an epoch or two and then flattens out. You generally don't want to train a model for any longer than is required for these accuracies to stabilize. The risk is overfitting, which results in the model performing well against test data but not so well with real-world data. One indication that a model is overfitting is a growing discrepancy between the training accuracy and the validation accuracy. For a great introduction to overfitting, see Overfitting in Machine Learning: What It Is and How to Prevent It.\n\nTo visualize the changes in training and validation accuracy as training progress, execute the following statements in a new notebook cell:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set()\nacc = hist.history['acc']\nval = hist.history['val_acc']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, '-', label='Training accuracy')\nplt.plot(epochs, val, ':', label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\nplt.plot()",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "[]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finish up by calling the model's evaluate method to determine how accurately the model is able to quantify the sentiment expressed in text based on the test data in x_test (reviews) and y_test (0s and 1s, or \"labels,\" indicating which reviews are positive and which are negative):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "scores = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 87.27%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We probably achieved an accuracy in the 85% to 90% range. That's acceptable considering we built the model from scratch (as opposed to using a pretrained neural network) and the training time was short even without a GPU. It is possible to achieve accuracies of 95% or higher with alternate neural network architectures, particularly recurrent neural networks (RNNs) that utilize Long Short-Term Memory (LSTM) layers. Keras makes it easy to build such networks, but training time can increase exponentially. The model that we built strikes a reasonable balance between accuracy and training time. However, if you would like to learn more about building RNNs with Keras, see Understanding LSTM and its Quick Implementation in Keras for Sentiment Analysis."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Use the Neural Network to Analyze Text for Sentiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The real test comes when we input text of your own into the model and see how it performs — that is, how adapt it is at quantifying the sentiment expressed in that text. In this unit, we'll write a Python function that accepts a text string as input, passes it to the model, and returns a sentiment score. Then you'll use the function to analyze the sentiment expressed in various text strings."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import string\nimport numpy as np\n\ndef analyze(text):\n    # Prepare the input by removing punctuation characters, converting\n    # characters to lower case, and removing words containing numbers\n    translator = str.maketrans('', '', string.punctuation)\n    text = text.translate(translator)\n    text = text.lower().split(' ')\n    text = [word for word in text if word.isalpha()]\n\n    # Generate an input tensor\n    input = [1]\n    for word in text:\n        if word in word_dict and word_dict[word] < top_words:\n            input.append(word_dict[word])\n        else:\n            input.append(2)\n    padded_input = sequence.pad_sequences([input], maxlen=max_review_length)\n\n    # Invoke the model and return the result\n    result = model.predict(np.array([padded_input][0]))[0][0]\n    return result",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "These statements define a function named analyze that accepts a string as input and returns a number from 0.0 to 1.0 quantifying the sentiment expressed in that string. The higher the number, the more positive the sentiment. The function cleans the input string, converts it into a list of integers referencing words in the dictionary created by the load_data function, and finally calls the model's predict function to score the text for sentiment. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "analyze('Easily the most stellar experience I have ever had.')",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "0.95449024"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "analyze('The long lines and poor customer service really turned me off.')",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "0.10032183"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "analyze('Their service was extremely excellent.')",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "0.9169482"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finish up by testing the model with input strings of your own. The results won't be perfect, but you should find that the model is reasonably adept at quantifying sentiment. Even though the model was trained with movie reviews, it isn't limited to analyzing movie reviews. That makes sense because there are inherent similarities between language expressing the like or dislike of a movie and words expressing feelings about other unrelated subjects."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}